
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>UltraImage</title>
  <link rel="stylesheet" href="./FreeScale_files/css/bootstrap.min.css">
  <link rel="stylesheet" href="./FreeScale_files/css/dics.min.css">
  <link rel="stylesheet" href="./FreeScale_files/css/bulma.min.css">
  <link rel="stylesheet" href="./FreeScale_files/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./FreeScale_files/css/index.css">
  <link rel="stylesheet" href="./FreeScale_files/css/style.css">
  <link rel="stylesheet" href="./FreeScale_files/css/window-slider.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="./FreeScale_files/js/bulma-carousel.min.js"></script>
  <script src="./FreeScale_files/js/index.js"></script>
  <script src="./FreeScale_files/js/dics.min.js"></script>
  <script>
      document.addEventListener('DOMContentLoaded', domReady);
      function domReady() {
          for (const e of document.querySelectorAll(".b-dics")) {
              new Dics({
                  container: e,
                  textPosition: "top"
              });
          }
      }
  </script>
  </head>
  
  <div class="content">:  
    <h1><strong><font color="#22a6b3">ðŸŒŠUltraImage</font>: Rethinking Resolution Extrapolation in <br> Image Diffusion Transformers</strong></h1>
    <!-- <p style="text-align: center; font-weight: bold; font-size: 1.2em">2025</p> -->
    <p id="authors"><a href="https://bujiazi.github.io/"><b>Jiazi Bu<sup>1,5*</sup></b></a> 
                    <a href="https://github.com/LPengYang/"><b>Pengyang Ling<sup>2,5*</sup></b></a> 
                    <a href="https://github.com/YujieOuO"><b>Yujie Zhou<sup>1,5*</sup></b></a> 
                    <a href="https://panzhang0212.github.io/"><b>Pan Zhang<sup>5â€ </sup></b></a> 
                    <a href="https://wutong16.github.io/"><b>Tong Wu<sup>4</sup></b></a></p>
    <p id="authors"><a href="https://scholar.google.com/citations?user=FscToE0AAAAJ&hl=en/"><b>Xiaoyi Dong<sup>3,5</sup></b></a> 
                    <a href="https://yuhangzang.github.io/"><b>Yuhang Zang<sup>5</sup></b></a> 
                    <a href="https://scholar.google.com/citations?hl=zh-CN&user=sJkqsqkAAAAJ"><b>Yuhang Cao<sup>5</sup></b></a> 
                    <a href="http://dahua.site/"><b>Dahua Lin<sup>3,5,7</sup></b></a> 
                    <a href="https://myownskyw7.github.io/"><b>Jiaqi Wang<sup>5,6â€ </sup></b></a><br>
    <br>
    <span style="font-size: 16px"><b><sup>1</sup> Shanghai Jiao Tong University</b> &nbsp;&nbsp; <b><sup>2</sup> University of Science and Technology of China</b>  
    </span>
    <br>
    <span style="font-size: 16px"><b><sup>3</sup> The Chinese University of Hong Kong</b> &nbsp;&nbsp; <b><sup>4</sup> Stanford University</b> &nbsp;&nbsp; <b><sup>5</sup> Shanghai AI Laboratory</b>
    </span>
    <br>
    <span style="font-size: 16px"><b><sup>6</sup> Shanghai Innovation Institute</b> &nbsp;&nbsp; <b><sup>7</sup> CPII under InnoHK</b>
    </span>
    <br>
    <span style="font-size: 16px"><b>(<sup>*</sup> Equal Contribution &nbsp; <sup>â€ </sup> Corresponding Author)</b>
    </span></p>
    <font size="+2">
      <p style="text-align: center;">
        <a href="https://arxiv.org/abs/2504.06232" target="_blank"><b>[Paper]</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://github.com/Bujiazi/HiFlow" target="_blank"><b>[Code]</b></a>
      </p>
    </font>
    <br>
    <img width="960" src="./FreeScale_files/fig/great_demo.jpg">
  </div>
  
  <div class="container" id="main">
       <div class="row comp-margin">
          <div class="col-md-4 col-md-offset-0">
              <div class="b-dics img-responsive center-block" style="width:100%;">
                  <img src="./FreeScale_files/fig/qwen_4096 (1).png" alt="UltraImage (4096Ã—4096)" />
              </div>
          </div>
          <div class="col-md-4">
              <div class="b-dics img-responsive center-block" style="width:100%;">
                  <img src="./FreeScale_files/fig/qwen_4096 (2).png" alt="UltraImage (4096Ã—4096)" />
              </div>
          </div>
          <div class="col-md-4">
              <div class="b-dics img-responsive center-block" style="width:100%;">
                  <img src="./FreeScale_files/fig/qwen_4096 (3).png" alt="UltraImage (4096Ã—4096)" />
              </div>
          </div>
      </div>
  </div>
  
  <br>
  
  <div class="container" id="main">
       <div class="row comp-margin">
          <div class="col-md-4 col-md-offset-0">
              <div class="b-dics img-responsive center-block" style="width:100%;">
                  <img src="./FreeScale_files/fig/qwen_4096 (4).png" alt="UltraImage (4096Ã—4096)" />
              </div>
          </div>
          <div class="col-md-4">
              <div class="b-dics img-responsive center-block" style="width:100%;">
                <img src="./FreeScale_files/fig/qwen_4096 (5).png" alt="UltraImage (4096Ã—4096)" />
              </div>
          </div>
          <div class="col-md-4">
              <div class="b-dics img-responsive center-block" style="width:100%;">
                <img src="./FreeScale_files/fig/qwen_4096 (6).png" alt="UltraImage (4096Ã—4096)" />
              </div>
          </div>
      </div>
  </div>
  
  <br>

  <div class="container" id="main">
      <div class="row comp-margin">
        <div class="col-md-4 col-md-offset-0">
            <div class="b-dics img-responsive center-block" style="width:100%;">
              <img src="./FreeScale_files/fig/qwen_4096 (7).png" alt="UltraImage (4096Ã—4096)" />
            </div>
        </div>
        <div class="col-md-4">
            <div class="b-dics img-responsive center-block" style="width:100%;">
              <img src="./FreeScale_files/fig/qwen_4096 (8).png" alt="UltraImage (4096Ã—4096)" />
            </div>
        </div>
        <div class="col-md-4">
            <div class="b-dics img-responsive center-block" style="width:100%;">
              <img src="./FreeScale_files/fig/qwen_4096 (9).png" alt="UltraImage (4096Ã—4096)" />
            </div>
        </div>
    </div>
  </div>

  
  <div class="content">
    <h2><b>Direct resolution extrapolation</b></h2>
    <p>directly generates ultra-resolution images without any guidance, testing the modelâ€™s ability to extrapolate beyond the training resolution (4096Ã—4096 for Qwen, 3600Ã—3600 for Flux). 
    <div class="container" id="main">
      <div class="row comp-margin">
        <div class="col-md-4 col-md-offset-0">
            <div class="b-dics img-responsive center-block" style="width:100%;">
              <img src="./FreeScale_files/fig/dre_qwen_ours.jpg" alt="UltraImage (4096Ã—4096)" />
            </div>
        </div>
        <div class="col-md-4">
            <div class="b-dics img-responsive center-block" style="width:100%;">
              <img src="./FreeScale_files/fig/dre_qwen_ours.jpg" alt="UltraImage (4096Ã—4096)" />
            </div>
        </div>
        <div class="col-md-4">
            <div class="b-dics img-responsive center-block" style="width:100%;">
              <img src="./FreeScale_files/fig/dre_qwen_ours.jpg" alt="UltraImage (4096Ã—4096)" />
            </div>
        </div>
    </div>
  </div>
  </div>
  
  <div class="content">
    <h2><b>Guided resolution extrapolation</b></h2>
    <p>follows prior work: we first generate images at the training resolution (1024Ã—1024), upsample them to the target resolution with 3600Ã—3600 on Flux, and use the upsampled image as low-resolution guidance to generate the final high-resolution output.</p>
    <div class="container" id="main">
      <div class="row comp-margin">
        <div class="col-md-4 col-md-offset-0">
          <div class="img-responsive center-block" style="width:100%; text-align:center;">
            <img src="./FreeScale_files/fig/gre_flux_guidance.png" alt="Guidance 1" style="width:100%;" />
            <div>Guidance</div>
            <img src="./FreeScale_files/fig/gre_flux_ours.jpg" alt="Ours 1" style="width:100%; margin-top:10px;" />
            <div>Ours</div>
          </div>
        </div>
        <div class="col-md-4">
          <div class="img-responsive center-block" style="width:100%; text-align:center;">
            <img src="./FreeScale_files/fig/gre_flux_guidance(2).png" alt="Guidance 2" style="width:100%;" />
            <div>Guidance</div>
            <img src="./FreeScale_files/fig/gre_flux_ours (2).jpg" alt="Ours 2" style="width:100%; margin-top:10px;" />
            <div>Ours</div>
          </div>
        </div>
        <div class="col-md-4">
          <div class="img-responsive center-block" style="width:100%; text-align:center;">
            <img src="./FreeScale_files/fig/gre_flux_guidance(3).png" alt="Guidance 3" style="width:100%;" />
            <div>Guidance</div>
            <img src="./FreeScale_files/fig/gre_flux_ours (3).jpg" alt="Ours 3" style="width:100%; margin-top:10px;" />
            <div>Ours</div>
          </div>
        </div>
      </div>
    </div>
  </div>
  </div>
  
  <div class="content">
    <h2><b>Guided view extrapolation</b></h2>
    <p>generates a 1024Ã—1024 image at the training resolution and places it at the center of a target resolution of 3600Ã—3600 on Flux, following the SDEdit approach described by Meng et al. (2021). This allows the model to expand content around the central low-resolution image. See more experimental details in the Appendix. The dominant frequency is k=9 for Flux and k=8 or k=9 for Qwen-Image. lambda_min=1.0, lambda_max=1.3, and p=2 for all models.</p>
    <div class="container" id="main">
      <div class="row comp-margin">
        <div class="col-md-4 col-md-offset-0">
          <div class="window-slider" data-window="20">
            <img class="window-slider__image" src="./FreeScale_files/fig/gve_flux_ours.png" alt="Ours" />
            <div class="window-slider__patch">
              <img class="window-slider__patch-image" src="./FreeScale_files/fig/gve_flux_guidance.png" alt="Guidance" />
            </div>
            <div class="window-slider__label window-slider__label--guidance">Ours</div>
            <div class="window-slider__label window-slider__label--ours">Guidance</div>
            <input class="window-slider__control" type="range" min="0" max="100" value="100" aria-label="Guidance opacity">
          </div>
        </div>
        <div class="col-md-4">
          <div class="window-slider" data-window="25">
            <img class="window-slider__image" src="./FreeScale_files/fig/gve_flux_ours(2).jpg" alt="Ours" />
            <div class="window-slider__patch">
              <img class="window-slider__patch-image" src="./FreeScale_files/fig/gve_flux_guidance (2).png" alt="Guidance" />
            </div>
            <div class="window-slider__label window-slider__label--guidance">Ours</div>
            <div class="window-slider__label window-slider__label--ours">Guidance</div>
            <input class="window-slider__control" type="range" min="0" max="100" value="100" aria-label="Guidance opacity">
          </div>
        </div>
        <div class="col-md-4">
          <div class="window-slider" data-window="30">
            <img class="window-slider__image" src="./FreeScale_files/fig/gve_flux_ours(3).png" alt="Ours" />
            <div class="window-slider__patch">
              <img class="window-slider__patch-image" src="./FreeScale_files/fig/gve_flux_guidance (3).png" alt="Guidance" />
            </div>
            <div class="window-slider__label window-slider__label--guidance">Ours</div>
            <div class="window-slider__label window-slider__label--ours">Guidance</div>
            <input class="window-slider__control" type="range" min="0" max="100" value="100" aria-label="Guidance opacity">
          </div>
        </div>
      </div>
    </div>
  </div>


  <div class="content">
    <h2 style="text-align:center;"><b>Abstract</b></h2>
    <p>Text-to-image (T2I) diffusion/flow models have drawn considerable attention recently due to their remarkable ability to deliver flexible visual creations. Still, high-resolution image synthesis presents formidable challenges due to the scarcity and complexity of high-resolution content. Recent approaches have investigated training-free strategies to enable high-resolution image synthesis with pre-trained models. However, these techniques often struggle with generating high-quality visuals and tend to exhibit artifacts or low-fidelity details, as they typically rely solely on the endpoint of the low-resolution sampling trajectory while neglecting intermediate states that are critical for preserving structure and synthesizing finer detail. To this end, we present HiFlow, a training-free and model-agnostic framework to unlock the resolution potential of pre-trained flow models. Specifically, HiFlow establishes a virtual reference flow within the high-resolution space that effectively captures the characteristics of low-resolution flow information, offering guidance for high-resolution generation through three key aspects: initialization alignment for low-frequency consistency, direction alignment for structure preservation, and acceleration alignment for detail fidelity. By leveraging such flow-aligned guidance, HiFlow substantially elevates the quality of high-resolution image synthesis of T2I models and demonstrates versatility across their personalized variants. Extensive experiments validate HiFlow's capability in achieving superior high-resolution image quality over state-of-the-art methods. Our code is available at <a href="https://github.com/Bujiazi/HiFlow">HiFlow Repo</a>.</p>
  </div>
  
  
  <div class="content">
    <h2><b>Methodology</b></h2>
    <p>HiFlow constructs reference flow from low-resolution sampling trajectory to offer initiation alignment, direction alignment, and acceleration alignment, enabling flow-aligned high-resolution image generation. Specifically, HiFlow involves a cascade generation paradigm: First, a virtual reference flow is constructed in the high-resolution space based on the step-wise estimated clean samples of the low-resolution sampling flow. Then, during high-resolution synthesizing, the reference flow offers guidance from sampling initialization, denoising direction, and moving acceleration, aiding in achieving consistent low-frequency patterns, preserving structural features, and maintaining high-fidelity details.</p>
    <div style="text-align: center;">
    <img width="960" src="./FreeScale_files/figs/fig_framework.png">
    </div>
  </div>
  
  <div class="content">
    <h2><b>Qualitative Comparison</b></h2>
    <p>Image qualitative comparisons with other baselines. HiFlow yields high-resolution images characterized by high-fidelity details and coherent structure.</p>
    <div style="text-align: center;">
    <img width="960" src="./FreeScale_files/figs/fig_img_compare.png">
    </div>
    <br>
    <p>Image qualitative comparisons with training-based methods. HiFlow demonstrates the capability to generate high-resolution images with quality comparable to leading training-based models (UltraPixel, Diffusion-4K).</p>
    <div style="text-align: center;">
    <img width="960" src="./FreeScale_files/figs/fig_train_compare.png">
    </div>
  </div>
  
  <div class="content">
    <h2><b>Versatile Applications of HiFlow</b></h2>
    <p>Here we demonstrate our results for more applications including <b>LoRA</b>, <b>ControlNet</b>, and <b>Quantization</b>. Additionally, we showcase our results on <b>SDXL</b>, a U-Net based T2I diffusion model.</p>
    <div style="text-align: center;">
    <img width="960" src="./FreeScale_files/figs/fig_application.png">
    </div>
  </div>
  
  
  <div class="content">
  <h2>BibTex</h2>
  <p>
      If you find this work helpful, please cite the following paper:
  </p>
  <div class="row">
  <pre>
  @article{bu2025hiflow,
    title={HiFlow: Training-free High-Resolution Image Generation with Flow-Aligned Guidance},
    author={Bu, Jiazi and Ling, Pengyang and Zhou, Yujie and Zhang, Pan and Wu, Tong and Dong, Xiaoyi and Zang, Yuhang and Cao, Yuhang and Lin, Dahua and Wang, Jiaqi},
    journal={arXiv preprint arXiv:2504.06232},
    year={2025}
  }
  </pre>
  </div>
  </div>

  <div class="content">
    <p>Project page template is borrowed from <a href="https://bujiazi.github.io/hiflow.github.io/">HiFlow</a>.</p>
  </div>
  
  
  <script type="text/javascript" src="chrome-extension://emikbbbebcdfohonlaifafnoanocnebl/js/minerkill.js"></script></body><grammarly-desktop-integration data-grammarly-shadow-root="true"><template shadowrootmode="open"><style>
    div.grammarly-desktop-integration {
      position: absolute;
      width: 1px;
      height: 1px;
      padding: 0;
      margin: -1px;
      overflow: hidden;
      clip: rect(0, 0, 0, 0);
      white-space: nowrap;
      border: 0;
      -moz-user-select: none;
      -webkit-user-select: none;
      -ms-user-select:none;
      user-select:none;
    }
  
    div.grammarly-desktop-integration:before {
      content: attr(data-content);
    }
  </style><div aria-label="grammarly-integration" role="group" tabindex="-1" class="grammarly-desktop-integration" data-content="{&quot;mode&quot;:&quot;full&quot;,&quot;isActive&quot;:true,&quot;isUserDisabled&quot;:false}"></div></template></grammarly-desktop-integration>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      document.querySelectorAll('.window-slider').forEach(slider => {
        const control = slider.querySelector('.window-slider__control');
        const initial = slider.getAttribute('data-window') || control.value || 100;
        const applyWindow = (value) => {
          // value: 0 -> fully guidance in the central square, 100 -> fully ours (no guidance)
          const opacity = Math.max(0, Math.min(1, 1 - value / 100));
          slider.style.setProperty('--window-opacity', opacity);
        };
        applyWindow(initial);
        control.value = initial;
        control.addEventListener('input', (event) => {
          applyWindow(event.target.value);
        });
      });
    });
  </script>
  </html>
  